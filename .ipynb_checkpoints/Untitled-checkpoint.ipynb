{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977416ca-a1c3-43bf-98d1-57d77c0f1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU pypdf\n",
    "# %pip install cryptography\n",
    "# %pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f1759f-7d64-49be-bf73-87cca8298f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "import os\n",
    "\n",
    "# Import relevant functionality\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "import ollama\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.agents import Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad90f318-760f-4375-af36-8b6f77f2c49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b021446-b02b-4b20-bdd2-eb270a84893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
    "                             temperature=0.9,\n",
    "                             max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2491e01-4ecb-431f-a3c6-9aede10fcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_your_pdf():\n",
    "    loader = PyPDFLoader(r\"C:\\Users\\ADMIN\\Documents\\AI_Crypto_V2\\Bank_Statement_Example_Final.pdf\")     # Enter the pdf you wish to chat with.\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, \n",
    "                                                   chunk_overlap=400)\n",
    "    docs = text_splitter.split_documents(data)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def finance_management_expert(human_prompt):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a retriever tool using Chroma vectorstore and GoogleGenerativeAIEmbeddings.\n",
    "    \n",
    "    This is the knowledge base for finance,management,administration,stocks,shares,\n",
    "    Sales & Marketing Analytics, Credit Risk Analytics, Financial Market Analytics,\n",
    "    Accounting, Bank Statement's. \n",
    "    It fetches information from pdf's and document's.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"... Running finance_management_expert--\")\n",
    "    \n",
    "    load_docs = load_your_pdf()\n",
    "    \n",
    "    \n",
    "    # Initialize the embedding model\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    \n",
    "    # Create the Chroma vectorstore from the documents\n",
    "    vectorstore = Chroma.from_documents(documents = load_docs, embedding=embeddings)\n",
    "\n",
    "    # Create the retriever from the vectorstore\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "\n",
    "    # Define the system prompt\n",
    "    system_prompt = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use 12 sentences maximum and keep the \"\n",
    "        \"answer concise. Present your answere point wise if necessary.\\n\\n{context}\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    response = rag_chain.invoke({\"input\": human_prompt})\n",
    "#     print(response)\n",
    "    print(\"\\n----------------------->\\n\")\n",
    "    return response\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e2de42-794c-4602-8061-581b99670f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(name=\"Finance_Management_Expert\", func=finance_management_expert,\n",
    "         description=\"This is the knowledge base for finance,management,administration and Bank Statement's. It fetches information from pdf's and document's.\")\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4315da-1ddb-4a91-9332-e3e16e72b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5085effc-0123-4067-ba6e-abd0c7e2fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I am Kami an AI/ML Engineer from Mumbai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :-  Okay Kami, how can I help you today?\n",
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is this document\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :-  Please specify which document you are referring to. I need more information to understand what you're asking about.\n",
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  whose statement is this\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :-  Please provide the statement you are referring to. I need the statement to identify who it belongs to.\n",
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me the 'account summary'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :-  Could you please specify which account summary you are referring to? I need more information to understand what you're asking about.\n",
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Balance brought forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :-  Could you please provide more context? I need to know which account or document you are referring to when you mention \"Balance brought forward\".\n",
      "\n",
      "----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "while True:\n",
    "    print(\"\\n----\")\n",
    "    human_prompt = input(\"You: \")\n",
    "    if human_prompt.lower().strip() == \"exit\":\n",
    "        print(\"Exiting chat. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "    for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content = human_prompt )]}, \n",
    "        config ):\n",
    "#         print(chunk)\n",
    "        \n",
    "        try:\n",
    "            message = chunk[\"agent\"][\"messages\"][0].content\n",
    "            print(\"Bot :- \", message)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb678254-1901-499d-aed8-5f5dd676f16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
